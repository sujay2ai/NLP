{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spaCy_Doc_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPUBA3U9cBY1igyl/QyLURS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VitikaJain25/NLP/blob/master/spaCy_Tutorial/spaCy_Doc_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DkEV7Cl0kmA",
        "colab_type": "text"
      },
      "source": [
        "# To find the percentage in the given text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ykr8orkxULF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b28f8342-11c7-4a91-d91d-ae03c2d2eb8a"
      },
      "source": [
        "from spacy.lang.en import English\n",
        "nlp = English()\n",
        "\n",
        "# Process the text\n",
        "doc = nlp(\"In 1990, more than 60% of people in East Asia were in extreme poverty. Now less than 4% are.\")\n",
        "\n",
        "# Iterate over the tokens in doc\n",
        "for token in doc:\n",
        "  # Check if the token resembles a number\n",
        "  if token.like_num:\n",
        "    # Get the next token in the document\n",
        "    next_token = doc[token.i+1]\n",
        "    # Check if the next token's text equals \"%\"\n",
        "    if next_token.text == \"%\":\n",
        "      print (\"Percentage found: \", token.text)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percentage found:  60\n",
            "Percentage found:  4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pd0ZVF0l1A5p",
        "colab_type": "text"
      },
      "source": [
        "# POS Tag"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYAz7qOC1EGe",
        "colab_type": "code",
        "outputId": "32d6107f-a66b-4c46-c170-935b80af7a4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import spacy\n",
        "\n",
        "# Loading the small English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "# Process text\n",
        "doc = nlp(\"She ate the pizza\")\n",
        "# Iterate over the tokens in doc\n",
        "for token in doc:\n",
        "  # Print the text and predicted POS tag\n",
        "  print(token.text, token.pos_)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "She PRON\n",
            "ate VERB\n",
            "the DET\n",
            "pizza NOUN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxIWRpYg2rCR",
        "colab_type": "text"
      },
      "source": [
        "# Syntactic Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FwUj_a92c7B",
        "colab_type": "code",
        "outputId": "3b18bfdb-903f-4552-f25f-8904a3be6c54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Predict how the words are related\n",
        "for token in doc:\n",
        "  # Print the text, predicted POS tag, predicted dependency label, and syntactical head token(Parent Token that this word is attached to)\n",
        "  print(token.text, token.pos_, token.dep_, token.head.text)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "She PRON nsubj ate\n",
            "ate VERB ROOT ate\n",
            "the DET det pizza\n",
            "pizza NOUN dobj ate\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12GSCRmI6vy8",
        "colab_type": "text"
      },
      "source": [
        "# Named Entities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osZbIWSI6zxq",
        "colab_type": "code",
        "outputId": "3a243977-dff4-49db-a6a4-ebb33577e86d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Process a text\n",
        "doc = nlp(\"Apple is looking at buying U.K. statup at $ 1 Billion\")\n",
        "# Iterate over predicted entries\n",
        "# \"doc.ents\" lets you access entries predicted by the model\n",
        "for ent in doc.ents:\n",
        "  # Print the entity text and its label\n",
        "  print(ent.text, ent.label_)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Apple ORG\n",
            "U.K. GPE\n",
            "$ 1 Billion MONEY\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ob0SbXxO9MBB",
        "colab_type": "text"
      },
      "source": [
        "# To get quick definitions of common tags and labels\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saafRDBo8_-i",
        "colab_type": "code",
        "outputId": "2e94ac50-2c4e-4ac0-9a2f-25841a980ea1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "spacy.explain(\"GPE\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Countries, cities, states'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYuevvbx9Oe5",
        "colab_type": "code",
        "outputId": "551b171d-8f86-4264-e536-691827d4534c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "spacy.explain(\"dobj\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'direct object'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZqPoOLtH_jV",
        "colab_type": "text"
      },
      "source": [
        "# Need For Rule Based Matcher"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DX1LMhpDGVZ_",
        "colab_type": "code",
        "outputId": "97745761-0b66-433e-ffe8-d7651e45e500",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Models are statistical and not always right. Whether their predictions \n",
        "# are correct depends on the training data and the text youâ€™re processing.\n",
        "# Here, we can see that \"Iphone X\" is not recognised as an entity.\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "text = \"Upcoming iPhone X release date leaked as Apple reveals pre-orders\"\n",
        "\n",
        "# Process the text\n",
        "doc = nlp(text)\n",
        "\n",
        "# Iterate over the entities\n",
        "for ent in doc.ents:\n",
        "    # Print the entity text and label\n",
        "    print(ent.text, ent.label_)\n",
        "\n",
        "# Get the span for \"iPhone X\"\n",
        "iphone_x = doc[1:3]\n",
        "\n",
        "# Print the span text\n",
        "print(\"Missing entity:\", iphone_x.text)\n",
        "\n",
        "\n",
        "# To overcome this, we have spaCy's rule-based matcher, which can help to\n",
        "# find certain words and phrases in text."
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Apple ORG\n",
            "Missing entity: iPhone X\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLRiSxSuIFXH",
        "colab_type": "text"
      },
      "source": [
        "# Rule Based Matcher"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofzt9ZgPH97M",
        "colab_type": "code",
        "outputId": "eea99b8a-4561-4b44-cea3-a7d7f707539c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import spacy\n",
        "# Import the Matcher\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "# Load a model and create nlp object\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Initialize the matcher with shared vocab\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "# Add the pattern to matcher\n",
        "pattern = [{\"TEXT\" : \"iPhone\"}, {\"TEXT\" : \"X\"}]\n",
        "matcher.add(\"IPHONE_PATTERN\", None, pattern)\n",
        "# matcher.add - lets you add a pattern\n",
        "# First argument - Unique id to identify which pattern was matched\n",
        "# Second argument - optional Callback\n",
        "# Third argument - pattern to match\n",
        "\n",
        "# Process some text\n",
        "doc = nlp(\"Upcoming iPhone X release date leaked\")\n",
        "\n",
        "# Call the matcher on the doc\n",
        "# Returns list of tupples. Each tupple consists of 3 values: Match id, Start index, End index of matched span\n",
        "matches = matcher(doc)\n",
        "\n",
        "# Iterate over the matches\n",
        "for match_id, start, end in matches:\n",
        "  # Get the matched span\n",
        "  matched_span = doc[start:end]\n",
        "  print(match_id)\n",
        "  print(start)\n",
        "  print(end)\n",
        "  print(matched_span.text)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9528407286733565721\n",
            "1\n",
            "3\n",
            "iPhone X\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4-wuxegMYDT",
        "colab_type": "text"
      },
      "source": [
        "# Another example \n",
        "- using Lexical Attributes\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0dpNuLqMXrI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "# Import the Matcher\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "# Load a model and create nlp object\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Initialize the matcher with shared vocab\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "# Add the pattern to matcher\n",
        "# Looking for 5 tokens: A token consisting of only digits, 3 case insensitive tokens \n",
        "# for 'fifa', 'world' and 'cup' and a token than consist of punctuation.\n",
        "pattern = [{\"IS_DIGIT\" : True},\n",
        "           {\"LOWER\" : \"fifa\"},\n",
        "           {\"LOWER\" : \"world\"},\n",
        "           {\"LOWER\" : \"cup\"},\n",
        "           {\"IS_PUNCT\" : True}]\n",
        "\n",
        "matcher.add(\"FIFA_PATTERN\", None, pattern)\n",
        "# matcher.add - lets you add a pattern\n",
        "# First argument - Unique id to identify which pattern was matched\n",
        "# Second argument - optional Callback\n",
        "# Third argument - pattern to match\n",
        "\n",
        "# Process some text\n",
        "doc = nlp(\"2018 FIFA World Cup: France won!\")\n",
        "\n",
        "# Call the matcher on the doc\n",
        "# Returns list of tupples. Each tupple consists of 3 values: Match id, Start index, End index of matched span\n",
        "matches = matcher(doc)\n",
        "\n",
        "# Iterate over the matches\n",
        "for match_id, start, end in matches:\n",
        "  # Get the matched span\n",
        "  matched_span = doc[start:end]\n",
        "  print(match_id)\n",
        "  print(start)\n",
        "  print(end)\n",
        "  print(matched_span.text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qgc7KjqtI9kp",
        "colab_type": "text"
      },
      "source": [
        "Another example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ver0-4qNfOw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "2f0bb0ca-aa43-4b6e-d007-032d9ffce597"
      },
      "source": [
        "import spacy\n",
        "# Import the Matcher\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "# Load a model and create nlp object\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Initialize the matcher with shared vocab\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "# Add the pattern to matcher\n",
        "# Looking for 2 tokens: A verb with a Lemma love followed by a noun\n",
        "pattern = [{\"LEMMA\" : \"love\" , \"POS\" : \"VERB\"}, {\"POS\" : \"NOUN\"}]\n",
        "\n",
        "matcher.add(\"DOG_CAT_PATTERN\", None, pattern)\n",
        "# matcher.add - lets you add a pattern\n",
        "# First argument - Unique id to identify which pattern was matched\n",
        "# Second argument - optional Callback\n",
        "# Third argument - pattern to match\n",
        "\n",
        "# Process some text\n",
        "doc = nlp(\"I loved dogs but now I love cats more.\")\n",
        "\n",
        "# Call the matcher on the doc\n",
        "# Returns list of tupples. Each tupple consists of 3 values: Match id, Start index, End index of matched span\n",
        "matches = matcher(doc)\n",
        "\n",
        "# Iterate over the matches\n",
        "for match_id, start, end in matches:\n",
        "  # Get the matched span\n",
        "  matched_span = doc[start:end]\n",
        "  print(match_id)\n",
        "  print(start)\n",
        "  print(end)\n",
        "  print(matched_span.text)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16454400285746368565\n",
            "1\n",
            "3\n",
            "loved dogs\n",
            "16454400285746368565\n",
            "6\n",
            "8\n",
            "love cats\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7m4ccwz7Qmzg",
        "colab_type": "text"
      },
      "source": [
        "# Using Operators and Quantifiers\n",
        "\n",
        "Lets you define how often a token should be matched"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZS5P10qNP-Y_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "9445d6e2-9081-47f7-8228-ca50899088f1"
      },
      "source": [
        "import spacy\n",
        "# Import the Matcher\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "# Load a model and create nlp object\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Initialize the matcher with shared vocab\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "# Add the pattern to matcher\n",
        "# Here, \"?\" operator makes the determiner token optional\n",
        "# So, it will match a token with Lemma 'buy' and an optional Article and a Noun\n",
        "pattern = [{\"LEMMA\" : \"buy\"}, {\"POS\" : \"DET\" , \"OP\" : \"?\"}, {\"POS\" : \"NOUN\"}]\n",
        "\n",
        "matcher.add(\"SMARTPHONE_PATTERN\", None, pattern)\n",
        "# matcher.add - lets you add a pattern\n",
        "# First argument - Unique id to identify which pattern was matched\n",
        "# Second argument - optional Callback\n",
        "# Third argument - pattern to match\n",
        "\n",
        "# Process some text\n",
        "doc = nlp(\"I bought a smartphone. Now I'm buying apps.\")\n",
        "\n",
        "# Call the matcher on the doc\n",
        "# Returns list of tupples. Each tupple consists of 3 values: Match id, Start index, End index of matched span\n",
        "matches = matcher(doc)\n",
        "\n",
        "# Iterate over the matches\n",
        "for match_id, start, end in matches:\n",
        "  # Get the matched span\n",
        "  matched_span = doc[start:end]\n",
        "  print(match_id)\n",
        "  print(start)\n",
        "  print(end)\n",
        "  print(matched_span.text)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3772001973323200979\n",
            "1\n",
            "4\n",
            "bought a smartphone\n",
            "3772001973323200979\n",
            "8\n",
            "10\n",
            "buying apps\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBZOTyqaSvMr",
        "colab_type": "text"
      },
      "source": [
        "Example for Operators and Quantifiers:\n",
        "\n",
        "{\"OP\" : \"!\"} - Negation : match 0 times\n",
        "\n",
        "{\"OP\" : \"?\"} - Optional : match 0 or 1 times\n",
        "\n",
        "{\"OP\" : \"+\"} - Match 1 or more times\n",
        "\n",
        "{\"OP\" : \"*\"} - Match 0 or more times"
      ]
    }
  ]
}